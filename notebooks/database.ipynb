{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5f6dfe0",
   "metadata": {},
   "source": [
    "### import selfmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16508364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "✅ environment is ready,root set to:l:\\Foundations of Machine Learning Frameworks\\LinearRegressionArchitecture_Workshop\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine, text\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "current_dir = Path(os.getcwd())\n",
    "BASE_DIR = current_dir.parent \n",
    "\n",
    "if str(BASE_DIR) not in sys.path:\n",
    "    sys.path.append(str(BASE_DIR))\n",
    "\n",
    "CONFIG_PATH = BASE_DIR / \"configs\" / \"experiment_config.yaml\"\n",
    "DATA_PROCESSED = BASE_DIR / \"data\" / \"processed\" / \"cleaned_data.csv\"\n",
    "\n",
    "print(f\"✅ environment is ready,root set to:{BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e0eb5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Table robot_telemetry ready and 39672 rows loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "except UnicodeDecodeError:\n",
    "\n",
    "    with open(CONFIG_PATH, \"r\", encoding=\"cp950\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "db_url = config.get(\"database\", {}).get(\"db_url\")\n",
    "target_table = config.get(\"database\", {}).get(\"table_name\", \"robot_telemetry\")\n",
    "\n",
    "if not db_url:\n",
    "    raise ValueError(\"❌ Database URL not found in config!\")\n",
    "\n",
    "\n",
    "engine = create_engine(db_url, pool_pre_ping=True)\n",
    "\n",
    "\n",
    "ddl = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {target_table} (\n",
    "  id BIGSERIAL PRIMARY KEY,\n",
    "  elapsed_seconds DOUBLE PRECISION NOT NULL,\n",
    "  axis1_smooth DOUBLE PRECISION NOT NULL\n",
    ");\n",
    "CREATE INDEX IF NOT EXISTS idx_{target_table}_id ON {target_table}(id);\n",
    "\"\"\"\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    for stmt in ddl.strip().split(\";\"):\n",
    "        s = stmt.strip()\n",
    "        if s: conn.execute(text(s))\n",
    "\n",
    "\n",
    "if not DATA_PROCESSED.exists():\n",
    "    raise FileNotFoundError(f\"❌ 找不到資料檔: {DATA_PROCESSED}\")\n",
    "\n",
    "df = pd.read_csv(DATA_PROCESSED)\n",
    "load_df = df[[\"Elapsed_Seconds\", \"Axis1_Smooth\"]].rename(columns={\n",
    "    \"Elapsed_Seconds\": \"elapsed_seconds\",\n",
    "    \"Axis1_Smooth\": \"axis1_smooth\"\n",
    "})\n",
    "\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    conn.execute(text(f\"TRUNCATE TABLE {target_table} RESTART IDENTITY;\"))\n",
    "\n",
    "load_df.to_sql(target_table, engine, if_exists=\"append\", index=False, method=\"multi\", chunksize=1000)\n",
    "\n",
    "print(f\"✅ Table {target_table} ready and {len(load_df)} rows loaded successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LRAWvenv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
